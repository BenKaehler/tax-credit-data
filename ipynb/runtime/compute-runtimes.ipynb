{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the environment\n",
    "-----------------------\n",
    "\n",
    "First we'll import various functions that we'll need for generating the report and configure the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os.path import join, expandvars\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from tax_credit.framework_functions import (runtime_make_test_data,\n",
    "                                            runtime_make_commands,\n",
    "                                            clock_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## project_dir should be the directory where you've downloaded (or cloned) the \n",
    "## tax-credit repository. \n",
    "project_dir = '../..'\n",
    "data_dir = join(project_dir, \"data\")\n",
    "\n",
    "results_dir = join(project_dir, 'temp_results_runtime')\n",
    "runtime_results = join(results_dir, 'runtime_results.txt')\n",
    "tmpdir = join(results_dir, 'tmp')\n",
    "\n",
    "ref_db_dir = join(project_dir, 'data/ref_dbs/gg_13_8_otus')\n",
    "ref_seqs = join(ref_db_dir, '99_otus_clean_515f-806r_trim250.fasta')\n",
    "ref_taxa = join(ref_db_dir, '99_otu_taxonomy_clean.tsv')\n",
    "\n",
    "num_iters = 1\n",
    "sampling_depths = [1] + list(range(2000,10001,2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate test datasets\n",
    "Subsample reference sequences to create a series of test datasets and references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runtime_make_test_data(ref_seqs, tmpdir, sampling_depths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import to qiime for q2-feature-classifier methods, train scikit-learn classifiers. We do not include the training step in the runtime analysis, because under normal operating conditions a reference dataset will be trained once, then re-used many times for any datasets that use the same marker gene (e.g., 16S rRNA). Separating the training step from the classification step was a conscious decision on part of the designers to make classification as quick as possible, and removing redundant training steps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSaved TaxonomicClassifier to: ../../temp_results_runtime/tmp/1.fna.nb.qza\u001b[0m\n",
      "\u001b[32mSaved TaxonomicClassifier to: ../../temp_results_runtime/tmp/2000.fna.nb.qza\u001b[0m\n",
      "\u001b[32mSaved TaxonomicClassifier to: ../../temp_results_runtime/tmp/4000.fna.nb.qza\u001b[0m\n",
      "\u001b[32mSaved TaxonomicClassifier to: ../../temp_results_runtime/tmp/6000.fna.nb.qza\u001b[0m\n",
      "\u001b[32mSaved TaxonomicClassifier to: ../../temp_results_runtime/tmp/8000.fna.nb.qza\u001b[0m\n",
      "\u001b[32mSaved TaxonomicClassifier to: ../../temp_results_runtime/tmp/10000.fna.nb.qza\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! qiime tools import --input-path {ref_taxa} --output-path {ref_taxa}.qza --type \"FeatureData[Taxonomy]\" --source-format HeaderlessTSVTaxonomyFormat\n",
    "\n",
    "for depth in sampling_depths:\n",
    "    tmpfile = join(tmpdir, str(depth)) + '.fna'\n",
    "    ! qiime tools import --input-path {tmpfile} --output-path {tmpfile}.qza --type \"FeatureData[Sequence]\"\n",
    "    ! qiime feature-classifier fit-classifier-naive-bayes --o-classifier {tmpfile}.nb.qza --i-reference-reads {tmpfile}.qza --i-reference-taxonomy {ref_taxa}.qza\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the method/parameter combinations\n",
    "\n",
    "Finally we define the method, parameter combintations that we want to test and command templates to execute.\n",
    "\n",
    "Template fields must adhere to following format:\n",
    "\n",
    "                      {0} = output directory\n",
    "                      {1} = input data\n",
    "                      {2} = reference sequences\n",
    "                      {3} = reference taxonomy\n",
    "                      {4} = method name\n",
    "                      {5} = other parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qiime1_setup = join(results_dir, '.bashrc')\n",
    "qiime1_template = ('bash -c \"source activate qiime1; source ' + qiime1_setup + '; '\n",
    "                   'assign_taxonomy.py -i {1} -o {0} -r {2} -t {3} -m {4} {5}\"')\n",
    "blast_template = ('qiime feature-classifier classify-consensus-blast --i-query {1}.qza --o-classification '\n",
    "                  '{0}/assign.tmp --i-reference-reads {2}.qza --i-reference-taxonomy {3}.qza {5}')\n",
    "vsearch_template = ('qiime feature-classifier classify-consensus-vsearch --i-query {1}.qza '\n",
    "                    '--o-classification {0}/assign.tmp --i-reference-reads {2}.qza --i-reference-taxonomy {3}.qza {5}')\n",
    "naive_bayes_template = ('qiime feature-classifier classify-sklearn  '\n",
    "                        '--o-classification {0}/assign.tmp --i-classifier {2}.nb.qza --i-reads {1}.qza {5}')\n",
    "\n",
    "# {method: template, method-specific params}\n",
    "methods = {\n",
    "    'rdp': (qiime1_template, '--confidence 0.5 --rdp_max_memory 16000'),\n",
    "    'uclust': (qiime1_template, '--min_consensus_fraction 0.51 --similarity 0.8 --uclust_max_accepts 3'),\n",
    "    'sortmerna': (qiime1_template, '--sortmerna_e_value 0.001 --min_consensus_fraction 0.51 --similarity 0.8 '\n",
    "                 '--sortmerna_best_N_alignments 3 --sortmerna_coverage 0.8'),\n",
    "    'blast' : (qiime1_template, '-e 0.001'),\n",
    "    'blast+' : (blast_template, '--p-evalue 0.001'),\n",
    "    'vsearch' : (vsearch_template, '--p-perc-identity 0.90'),\n",
    "    'naive-bayes': (naive_bayes_template, '--p-confidence 0.7')\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the list of commands and run them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will vary the size of the reference database and search a single sequence against it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "commands_a = runtime_make_commands(tmpdir, tmpdir, methods, ref_taxa,\n",
    "                                   sampling_depths, num_iters=1, subsample_ref=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will vary the number of query seqs, and keep the number of ref seqs constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "commands_b = runtime_make_commands(tmpdir, tmpdir, methods, ref_taxa,\n",
    "                                   sampling_depths, num_iters=1, subsample_ref=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first command in each list and the total number of commands as a sanity check..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "('bash -c \"source activate qiime1; source ../../temp_results_runtime/.bashrc; assign_taxonomy.py -i ../../temp_results_runtime/tmp/1.fna -o ../../temp_results_runtime/tmp -r ../../temp_results_runtime/tmp/2000.fna -t ../../data/ref_dbs/gg_13_8_otus/99_otu_taxonomy_clean.tsv -m sortmerna --sortmerna_e_value 0.001 --min_consensus_fraction 0.51 --similarity 0.8 --sortmerna_best_N_alignments 3 --sortmerna_coverage 0.8\"', 'sortmerna', '1', '2000', 0)\n",
      "('qiime feature-classifier classify-consensus-vsearch --i-query ../../temp_results_runtime/tmp/10000.fna.qza --o-classification ../../temp_results_runtime/tmp/assign.tmp --i-reference-reads ../../temp_results_runtime/tmp/10000.fna.qza --i-reference-taxonomy ../../data/ref_dbs/gg_13_8_otus/99_otu_taxonomy_clean.tsv.qza --p-perc-identity 0.90', 'vsearch', '10000', '10000', 0)\n"
     ]
    }
   ],
   "source": [
    "print(len(commands_a + commands_b))\n",
    "print(commands_a[1])\n",
    "print(commands_b[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parallel(n_jobs=23)(delayed(clock_runtime)(command, runtime_results, force=False) for command in (list(set(commands_a + commands_b))));"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
